import sentencepiece as spm

# Criando um arquivo de texto para treinar o tokenizador
texto_exemplo = """              """

# Salvar o texto no arquivo
with open("dados.txt", "w") as f:
    f.write(texto_exemplo)

# Treinando um modelo de SentencePiece
spm.SentencePieceTrainer.Train("--input=dados.txt --model_prefix=meu_modelo --vocab_size=50 --character_coverage=1.0")

# Carregar o modelo treinado
sp = spm.SentencePieceProcessor()
sp.load("meu_modelo.model")
